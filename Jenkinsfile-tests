#!/usr/bin/env groovy

def storeArtifacts() {
    sh './systemtests/scripts/store_kubernetes_info.sh "artifacts/openshift-info/"'
    sh './systemtests/scripts/collect_logs.sh "/tmp/testlogs" "artifacts/openshift-logs"'
    sh 'rm -rf /tmp/testlogs'
}

def tearDownOpenshift() {
    echo "tear down openshift"
    sh './systemtests/scripts/teardown-openshift.sh'
}

pipeline {
    agent {
        node {
            label 'enmasse'
        }
    }
    parameters {
        string(name: 'TEST_CASE', defaultValue: '', description: 'maven parameter for executing specific tests')
        string(name: 'MAILING_LIST', defaultValue: '', description: '')
        string(name: 'BUILD_TAG', defaultValue: '', description: 'version of images')
        string(name: 'COMMIT_SHA', defaultValue: '', description: 'Commit sha1')
    }
    options {
        timeout(time: 5, unit: 'HOURS')
    }
    environment {
        CORES_DIR = "/tmp/cores"
    }
    stages {
        stage('add description') {
            steps {
                script {
                    currentBuild.description = "related build: ${params.BUILD_TAG}"
                }
            }
        }
        stage('clean') {
            steps {
                cleanWs()
                sh 'docker stop $(docker ps -q) || true'
                sh 'docker rm $(docker ps -a -q) -f || true'
                sh 'docker rmi $(docker images -q) -f || true'
            }
        }
        stage('checkout') {
            steps {
                checkout scm
                sh "git checkout ${params.COMMIT_SHA}"
                sh 'git submodule update --init --recursive'
                sh 'rm -rf artifacts && mkdir -p artifacts'
            }
        }
        stage('start openshift') {
            steps {
                timeout(time: 10, unit: 'MINUTES') {
                    sh './systemtests/scripts/setup-openshift.sh "templates/install"'
                    sh 'sudo chmod -R 777 /var/lib/origin/openshift.local.config'
                }
            }
        }
        stage('system tests') {
            environment {
                ARTIFACTS_DIR = 'artifacts'
                JOB_NAME_SUB = "${String.format("%.15s", JOB_NAME)}"
                OPENSHIFT_PROJECT = "${JOB_NAME_SUB}${BUILD_NUMBER}"
                DOCKER_REGISTRY = credentials('docker-registry-host')
                DOCKER_CREDENTIALS = credentials('docker-registry-credentials')
                DOCKER_PASS = "${env.DOCKER_CREDENTIALS_PSW}"
                DOCKER_USER = "${env.DOCKER_CREDENTIALS_USR}"
                COMMIT = "${params.BUILD_TAG}"
                USE_DUMMY_ADDRESS = true
            }
            steps {
                withCredentials([string(credentialsId: 'openshift-host', variable: 'OPENSHIFT_URL'), usernamePassword(credentialsId: 'openshift-credentials', passwordVariable: 'OPENSHIFT_PASSWD', usernameVariable: 'OPENSHIFT_USER')]) {
                    sh 'make -C templates || true'
                    sh "sudo ./systemtests/scripts/enable_core_dumps.sh ${env.CORES_DIR}"
                    sh "./systemtests/scripts/run_test_component.sh templates/install /var/lib/origin/openshift.local.config/master/admin.kubeconfig ${params.TEST_CASE} ''"
                }
            }
        }
    }
    post {
        always {
            storeArtifacts() //store artifacts if build was aborted - due to timeout reached
            //store test results from build and system tests
            junit '**/TEST-*.xml'

            //archive test results and openshift logs
            archive '**/TEST-*.xml'
            archive 'templates/install/**'
            sh "sudo ./systemtests/scripts/compress_core_dumps.sh ${env.CORES_DIR} artifacts"
            archive 'artifacts/**'
            tearDownOpenshift()
            sh "./systemtests/scripts/check_and_clear_cores.sh ${env.CORES_DIR}"
        }
        failure {
            echo "build failed"
            mail to: "$MAILING_LIST", subject: "EnMasse build has finished with ${result}", body: "See ${env.BUILD_URL}"
        }
    }
}
